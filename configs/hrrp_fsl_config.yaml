# Configuration for Few-Shot HRRP Recognition (CMSA-HRRP)

# --- Data Configuration ---
data:
  simulated_path: './datasets/simulated_hrrp' # 仿真数据根目录
  measured_path: './datasets/measured_hrrp'   # 实测数据根目录
  # 定义基类和新类 (请根据你的实际12+3类目标填写)
  # 示例: 假设仿真数据中有 BTR, T72, ZSU234; 实测中有 CAR, VAN, TRUCK
  # 确保名称与 .mat 文件名前缀一致
  base_classes:
    - 'EA-18G'         # Simulated
    - 'EP-3E'         # Simulated
    - 'F2'      # Simulated
    - 'F15'        # Simulated
    - 'F16'       # Simulated
    - 'F18'         # Simulated
    - 'F22'      # Simulated
    - 'F35'          # Simulated
    - 'IDF'         # Simulated
    - '捕食者'         # Simulated (Example)
    - '幻影2000'         # Simulated (Example)
    - '全球鹰'      # Simulated (Example)
  novel_classes:
    - 'F35'          # Simulated
    - 'IDF'         # Simulated
    - '捕食者'         # Simulated (Example)
    - '幻影2000'         # Simulated (Example)
    - '全球鹰'      # Simulated (Example)
#    - 'an26'         # Measured
#    - 'yar42'         # Measured
#    - 'citation'       # Measured
  target_length: 1000 # HRRP处理后的目标长度 (实测数据会被填充)
  normalization: 'max' # 归一化方法: 'max', 'log_max', 'none'

# --- Few-Shot Learning Configuration ---
fsl:
  n_way: 5          # N-way classification
  k_shot: 1         # K-shot learning (support samples per class)
  q_query: 15       # Query samples per class in each episode
  test_episodes: 6 # Number of episodes for testing

# --- Model Configuration ---
model:
  hrrp_encoder:
    output_dim: 512   # f_H 输出维度 (需要与 h_A 输入匹配)
    # Add other encoder specific params if needed (e.g., layers, kernel_size)
  alignment_module:
    hidden_dim: 1024  # h_A 隐藏层维度
    # Output dim determined by VLM text encoder
  fusion_module:      # h_F (Optional, for semantic enhancement)
    hidden_dim: 4096  # Example, similar to SemFew's SemAlign hidden dim
    # Input dim = aligned_hrrp_dim + semantic_dim
    # Output dim = aligned_hrrp_dim
    kappa: 0.5        # Prototype fusion factor (0: no SemEnh, 1: only recon)
  foundation_model:
    name: 'RemoteCLIP' # 'RemoteCLIP' or 'SARATRX_Adapted' etc.
    variant: 'ViT-B-32' # e.g., 'ViT-B-32', 'RN50' for RemoteCLIP
    text_encoder_dim: 512 # VLM text encoder output dim (MUST match alignment output)

# --- Training Configuration (for Alignment Module) ---
training:
  alignment:
    epochs: 10
    batch_size: 128
    lr: 0.0001
    optimizer: 'Adam'
    loss_type: 'cosine' # 'cosine' or 'l1' or 'mse'
    # Add scheduler params if needed
  fsl_meta_training: # (Optional, if h_F needs meta-training)
    epochs: 50
    lr: 0.001
    # ... other meta-learning specific params

# --- Semantics Configuration ---
semantics:
  # Path to pre-generated semantic features file
  feature_path: './semantic_features/hrrp_semantics_remoteclip_vitb32_gpt.pth'
  # Parameters used during generation (for reference/tracking)
  generation:
    llm: 'GPT-3.5-turbo'
    text_type: 'gpt' # Corresponds to file naming convention

# --- Paths Configuration ---
paths:
  checkpoints: './checkpoints'
  logs: './logs'
  # Add specific subdirs if needed, e.g., checkpoints/alignment_module

# --- Other Hyperparameters ---
num_workers: 4
seed: 410073